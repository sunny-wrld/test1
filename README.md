# Aurora Edge - Assistente de IA Offline

## ğŸ“± Sobre o Projeto

Aurora Edge Ã© um assistente de IA completamente offline para Android, que roda modelos de linguagem quantizados localmente no dispositivo, sem necessidade de conexÃ£o com a internet.

## ğŸš€ Guia RÃ¡pido: Testar no Celular

**Quer testar no seu celular?** Veja o **[Guia Completo de Teste](./GUIA_TESTE_CELULAR.md)** com instruÃ§Ãµes passo a passo detalhadas!

**Resumo rÃ¡pido:**
1. Ative modo desenvolvedor no celular
2. Conecte via USB e instale o app
3. Baixe um modelo GGUF (ex: Phi-2 Q4_0)
4. Copie o modelo para a pasta do app
5. Ative modo aviÃ£o e teste offline!

## ğŸš€ CaracterÃ­sticas

- âœ… **100% Offline** - Zero dependÃªncia de internet
- âœ… **Privacidade Total** - Dados nunca saem do dispositivo
- âœ… **Baixa LatÃªncia** - Respostas instantÃ¢neas
- âœ… **Modelos Quantizados** - 50-300MB de tamanho
- âœ… **Suporte a GGUF** - Formatos Llama, Phi, Gemma, Mistral

## ğŸ“‹ Requisitos

- Android Studio Hedgehog ou superior
- Android SDK 24+ (Android 7.0+)
- NDK r25c ou superior
- Dispositivo com pelo menos 2GB RAM
- 500MB de armazenamento livre

## ğŸ”§ Como Compilar

### 1. Clonar o RepositÃ³rio

```bash
git clone <repository-url>
cd AuroraEdge
```

### 2. Configurar Llama.cpp

```bash
# Clonar llama.cpp como submodule
git submodule add https://github.com/ggerganov/llama.cpp.git third_party/llama.cpp
git submodule update --init --recursive
```

### 3. Baixar Modelo

Baixe um modelo quantizado GGUF (recomendado: Phi-2 Q4_0):

```bash
# Criar diretÃ³rio de modelos
mkdir -p app/src/main/assets/models

# Baixar modelo (exemplo com Phi-2)
wget https://huggingface.co/microsoft/phi-2-gguf/resolve/main/phi-2.Q4_0.gguf \
  -O app/src/main/assets/models/phi-2-q4_0.gguf
```

**Modelos Recomendados:**
- Phi-2 Q4_0 (~1.6GB) - Melhor qualidade
- Gemma 2B Q4_0 (~1.4GB) - Boa qualidade
- Mistral 7B Q4_0 (~4GB) - Alta qualidade (requer mais RAM)

### 4. Compilar no Android Studio

1. Abra o projeto no Android Studio
2. Aguarde a sincronizaÃ§Ã£o do Gradle
3. Conecte um dispositivo Android ou inicie um emulador
4. Clique em "Run" (Shift+F10)

### 5. Compilar via Linha de Comando

```bash
./gradlew assembleDebug
adb install app/build/outputs/apk/debug/app-debug.apk
```

## ğŸ§ª Como Testar Offline

### 1. Preparar Dispositivo

```bash
# Instalar APK
adb install app-debug.apk

# Copiar modelo para o dispositivo
adb push app/src/main/assets/models/phi-2-q4_0.gguf \
  /sdcard/Android/data/com.auroraedge.app/files/models/phi-2-q4_0.gguf
```

### 2. Testar Offline

1. **Ativar Modo AviÃ£o** no dispositivo
2. Abrir o app Aurora Edge
3. Aguardar carregamento do modelo (30-60 segundos)
4. Enviar mensagem de teste: "OlÃ¡, como vocÃª estÃ¡?"
5. Verificar resposta gerada localmente

### 3. Testar FunÃ§Ã£o de Resumo

1. Clicar no botÃ£o "ğŸ“„" (resumir)
2. Colar um texto longo
3. Verificar resumo gerado

## ğŸ”„ Como Trocar Modelo

### Via Interface do App

1. Abrir ConfiguraÃ§Ãµes
2. Selecionar "Modelo de IA"
3. Escolher modelo da lista
4. Aguardar carregamento

### Via Arquivos

1. Copiar novo modelo GGUF para:
   ```
   /sdcard/Android/data/com.auroraedge.app/files/models/
   ```
2. Reiniciar o app
3. O app detectarÃ¡ automaticamente

### Formatos Suportados

- GGUF (Q4_0, Q4_1, Q5_0, Q5_1, Q8_0)
- ONNX (futuro)

## âš¡ OtimizaÃ§Ãµes de Desempenho

### 1. Reduzir Tamanho do Modelo

Use quantizaÃ§Ã£o mais agressiva:
- Q4_0: Boa qualidade, ~1.6GB
- Q3_K_M: Qualidade mÃ©dia, ~1.2GB
- Q2_K: Qualidade bÃ¡sica, ~800MB

### 2. Ajustar ParÃ¢metros de InferÃªncia

Edite `AIModelManager.kt`:

```kotlin
private const val MAX_TOKENS = 256  // Reduzir de 512
private const val TEMPERATURE = 0.8f  // Aumentar para respostas mais criativas
private const val TOP_P = 0.95f  // Aumentar diversidade
```

### 3. Usar GPU (NNAPI)

Para dispositivos com GPU/NPU:

```kotlin
// Em AIModelManager.kt
ctx->params.n_gpu_layers = 20;  // Usar 20 camadas na GPU
```

### 4. Threads de CPU

Ajuste nÃºmero de threads:

```kotlin
ctx->params.n_threads = 4;  // Aumentar se tiver mais cores
```

### 5. Contexto Menor

Reduza o contexto se tiver pouca RAM:

```kotlin
ctx->params.n_ctx = 1024;  // Reduzir de 2048
```

## ğŸ“ Estrutura do Projeto

```
AuroraEdge/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/auroraedge/app/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ChatActivity.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ AIModelManager.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ChatMessage.kt
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adapter/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ ChatAdapter.kt
â”‚   â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_jni.cpp
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ res/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ values/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ drawable/
â”‚   â”‚   â”‚   â””â”€â”€ AndroidManifest.xml
â”‚   â”‚   â””â”€â”€ test/
â”‚   â””â”€â”€ build.gradle.kts
â”œâ”€â”€ third_party/
â”‚   â””â”€â”€ llama.cpp/
â””â”€â”€ README.md
```

## ğŸ› Troubleshooting

### Modelo nÃ£o carrega

- Verifique se o arquivo GGUF estÃ¡ no diretÃ³rio correto
- Confirme que hÃ¡ espaÃ§o suficiente (500MB+)
- Verifique logs: `adb logcat | grep AIModelManager`

### Respostas muito lentas

- Reduza `MAX_TOKENS`
- Use modelo menor (Q3_K_M ou Q2_K)
- Feche outros apps para liberar RAM

### App trava ao iniciar

- Verifique se o dispositivo tem RAM suficiente (2GB+)
- Tente modelo menor
- Reinicie o dispositivo

### Erro de compilaÃ§Ã£o JNI

- Verifique se NDK estÃ¡ instalado
- Confirme versÃ£o do NDK (r25c+)
- Limpe build: `./gradlew clean`

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT. Veja LICENSE para detalhes.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra uma issue ou pull request.

## ğŸ“§ Contato

Para dÃºvidas ou suporte, abra uma issue no repositÃ³rio.

